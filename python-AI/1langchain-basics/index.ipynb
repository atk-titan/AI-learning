{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9baae364",
   "metadata": {},
   "source": [
    "## Getting Started With Langchain\n",
    "\n",
    "- **Simple LLM calls with streaming**\n",
    "- **Dynamic prompt templates** (translation app)\n",
    "- **Building chains** (story generator with analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03d8645c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "841b8679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca3eab34",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[ \"GROQ_API_KEY\" ] = os.getenv( \"GROQ_API_KEY\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34255d94",
   "metadata": {},
   "source": [
    "### Example 1:  Simple LLM Call with streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d07c9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bff4684",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_chat_model(\"groq:llama-3.1-8b-instant\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2420ca84",
   "metadata": {},
   "source": [
    "### Create Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2339f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(\"You are a helpful AI assistant\"),\n",
    "    HumanMessage(\"what are the top 2 benefits of using langchain?\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e69c03",
   "metadata": {},
   "source": [
    "### Invoke the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93cf7894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='LangChain is an open-source framework for building large language models. The top 2 benefits of using LangChain are:\\n\\n1. **Ease of Use and Integration**: LangChain provides a simple and intuitive API for building and integrating large language models into applications. It allows developers to easily load and use pre-trained models, as well as create and train custom models. This makes it easier for developers to focus on building their applications without dealing with the complexities of model management.\\n\\n2. **Flexibility and Customizability**: LangChain provides a highly flexible framework for building large language models. It allows developers to create custom pipelines, integrate multiple models, and add custom logic to their applications. This flexibility makes it possible to build highly specialized and tailored models that can perform a wide range of tasks.\\n\\nThese benefits make LangChain a powerful tool for developers looking to build and deploy large language models in their applications.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 180, 'prompt_tokens': 53, 'total_tokens': 233, 'completion_time': 0.356552019, 'prompt_time': 0.002733869, 'queue_time': 0.049526183, 'total_time': 0.359285888}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_0f5c9bc037', 'finish_reason': 'stop', 'logprobs': None}, id='run--f0621497-205b-4384-b445-40395d7b0948-0', usage_metadata={'input_tokens': 53, 'output_tokens': 180, 'total_tokens': 233})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response  = model.invoke(messages)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4404784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChain is an open-source framework for building large language models. The top 2 benefits of using LangChain are:\\n\\n1. **Ease of Use and Integration**: LangChain provides a simple and intuitive API for building and integrating large language models into applications. It allows developers to easily load and use pre-trained models, as well as create and train custom models. This makes it easier for developers to focus on building their applications without dealing with the complexities of model management.\\n\\n2. **Flexibility and Customizability**: LangChain provides a highly flexible framework for building large language models. It allows developers to create custom pipelines, integrate multiple models, and add custom logic to their applications. This flexibility makes it possible to build highly specialized and tailored models that can perform a wide range of tasks.\\n\\nThese benefits make LangChain a powerful tool for developers looking to build and deploy large language models in their applications.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbac17ed",
   "metadata": {},
   "source": [
    "### Streaming example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0103869d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is an open-source framework for building large language models (LLMs). Based on my knowledge cutoff in 2023, here are the top 2 benefits of using LangChain:\n",
      "\n",
      "1. **Modular and Extensible Architecture**: LangChain's modular design allows developers to easily integrate and combine different components, such as LLMs, databases, and APIs, to create custom workflows and applications. This flexibility enables developers to build complex systems that can handle various tasks, from simple question-answering to more advanced use cases like conversational AI and content generation.\n",
      "\n",
      "2. **High-Performance and Scalability**: LangChain is optimized for performance, making it suitable for large-scale applications that require processing high volumes of data and generating responses quickly. Its ability to scale horizontally and handle concurrent requests enables developers to build robust and efficient systems that can handle increased traffic and user engagement.\n",
      "\n",
      "Please note that LangChain is a rapidly evolving technology, and its features and benefits may have changed since my knowledge cutoff date. For the most up-to-date information, I recommend checking the official LangChain documentation and community resources."
     ]
    }
   ],
   "source": [
    "for chunk in model.stream(messages):\n",
    "    print(chunk.content,end=\"\",flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4da96b3",
   "metadata": {},
   "source": [
    "### Dynamic Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7578044c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "translation_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\" , \"you are a professional translator. Translate the following {text} from {source_language} to {target_language}.\"),\n",
    "    (\"user\", \"{text}\")\n",
    "])\n",
    "\n",
    "prompt = translation_template.invoke({\n",
    "    \"source_language\":\"English\",\n",
    "    \"target_language\":\"Spanish\",\n",
    "    \"text\":\"Hello, how are you? and also what are you doing these days?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "571f4c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='you are a professional translator. Translate the following Hello, how are you? and also what are you doing these days? from English to Spanish.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Hello, how are you? and also what are you doing these days?', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb665164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The translation of \"Hello, how are you? and also what are you doing these days?\" from English to Spanish is:\\n\\n\"Hola, ¿cómo estás? Y también, ¿qué estás haciendo estos días?\"\\n\\nHowever, a more common and natural way to phrase this in Spanish would be:\\n\\n\"Hola, ¿cómo estás? ¿Y qué tal? ¿Qué has estado haciendo últimamente?\"\\n\\nHere\\'s a breakdown of the translation:\\n\\n- \"Hello\" is translated to \"Hola\"\\n- \"how are you\" is translated to \"¿cómo estás?\"\\n- \"and also\" is translated to \"Y también\" or \"¿Y qué tal?\"\\n- \"what are you doing\" is translated to \"¿qué estás haciendo\"\\n- \"these days\" is translated to \"estos días\" or \"últimamente\" (meaning \"lately\" or \"recently\")'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated_model = model.invoke(prompt)\n",
    "translated_model.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64e9b84",
   "metadata": {},
   "source": [
    "### Building the first chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2cae6b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def createStoryChain():\n",
    "    # Template for story generation\n",
    "    storyPrompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\",\"you are creative storyteller. Write a short and engaging story based on the given theme, character and settings. Maintain the narrative style and rarly break the third wall. Make sure the story is interesting and dont copy the an existing story. Make it exciting as possible.\"),\n",
    "        (\"user\",\"Theme: {theme}\\n Main character: {character}\\n Setting: {setting}\")\n",
    "    ])\n",
    "\n",
    "    # Template for story analysis\n",
    "    analysisPrompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\",\"You are a litery story critic. Analyze the following story and give insights like symbolisms how and what is inspired from where like scriptures or folklores or epics from any country. give appropriate ratings based on points Ranging from 0-3 and also provide ways in which the story can be made better.\"),\n",
    "        (\"user\",\"story: {story}\")\n",
    "    ])\n",
    "\n",
    "    # Creating the forst chain\n",
    "    storyChain = (\n",
    "        storyPrompt | model | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    def analyzeStory(storyOutput):\n",
    "        return { \"story\" : storyOutput }\n",
    "    # Creating an analysis chain\n",
    "    analysisChain = (\n",
    "        storyChain | RunnableLambda(analyzeStory) | analysisPrompt | model | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    return analysisChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "30a9c680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['character', 'setting', 'theme'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='you are creative storyteller. Write a short and engaging story based on the given theme, character and settings. Maintain the narrative style and rarly break the third wall. Make sure the story is interesting and dont copy the an existing story. Make it exciting as possible.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['character', 'setting', 'theme'], input_types={}, partial_variables={}, template='Theme: {theme}\\n Main character: {character}\\n Setting: {setting}'), additional_kwargs={})])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001E28F5E9550>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001E28F725990>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()\n",
       "| RunnableLambda(analyzeStory)\n",
       "| ChatPromptTemplate(input_variables=['story'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a litery story critic. Analyze the following story and give insights like symbolisms how and what is inspired from where like scriptures or folklores or epics from any country. give appropriate ratings based on points Ranging from 0-3 and also provide ways in which the story can be made better.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['story'], input_types={}, partial_variables={}, template='story: {story}'), additional_kwargs={})])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001E28F5E9550>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001E28F725990>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = createStoryChain()\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1c697216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Story Analysis:**\n",
      "\n",
      "The provided story is a fantasy tale that explores the themes of power, politics, and self-discovery. It combines elements of mythology, folklore, and world-building to create a rich and immersive setting. The story draws inspiration from various sources, including:\n",
      "\n",
      "1. **Mythology and Folklore:** The world of Eridoria, with its diverse continents and magical creatures, bears similarities to J.R.R. Tolkien's Middle-earth. The concept of reincarnation and the idea of a mystical realm are reminiscent of Buddhist and Hindu mythologies.\n",
      "2. **Epic Literature:** The story's focus on politics, power struggles, and alliances is reminiscent of epic tales like _The Iliad_ and _The Odyssey_. The character of Kael, with his pride and sense of purpose, echoes the likes of Achilles from Greek mythology.\n",
      "3. **Fantasy Literature:** The story's use of magic, secret societies, and a council of elders is similar to the works of authors like George R.R. Martin and Patrick Rothfuss.\n",
      "\n",
      "**Symbolisms:**\n",
      "\n",
      "1. **The World of Eridoria:** Eridoria represents a world of possibilities and challenges, where characters must navigate complex webs of power and politics.\n",
      "2. **The Council of Elders:** The council symbolizes the old guard, struggling to maintain control and relevance in a rapidly changing world.\n",
      "3. **The Order of the White Rose:** The Order represents a force of change and rebellion, striving to bring about a new era of freedom and justice.\n",
      "4. **Kael and Arjun's Relationship:** The bond between Kael and Arjun serves as a symbol of friendship and trust, forged in the face of adversity and uncertainty.\n",
      "\n",
      "**Ratings:**\n",
      "\n",
      "* **Imagination and World-Building:** 2.5/3 (The world of Eridoria is rich and immersive, but some aspects feel familiar and lack originality.)\n",
      "* **Character Development:** 2.5/3 (Arjun and Kael are well-defined characters, but Lyra and other supporting characters feel somewhat one-dimensional.)\n",
      "* **Plot and Pacing:** 2/3 (The story moves at a steady pace, but some plot threads feel underdeveloped and convenient.)\n",
      "* **Themes and Symbolism:** 2.5/3 (The themes of power, politics, and self-discovery are well-explored, but some symbolism feels heavy-handed.)\n",
      "\n",
      "**Suggestions for Improvement:**\n",
      "\n",
      "1. **Add more nuance to supporting characters:** Give Lyra and other supporting characters more depth and complexity to make them feel more realistic and engaging.\n",
      "2. **Develop the world of Eridoria further:** While the world is rich and immersive, some aspects feel underdeveloped. Consider adding more details about the history, cultures, and politics of the different continents.\n",
      "3. **Introduce conflicts and challenges:** While the story has a clear direction, it feels somewhat straightforward. Introduce more conflicts, twists, and challenges to make the narrative more engaging and unpredictable.\n",
      "4. **Explore the consequences of actions:** Consider showing the consequences of the characters' actions, rather than relying on convenient plot devices and coincidences.\n",
      "\n",
      "Overall, the story has a lot of potential, and with some refinement, it could become an engaging and immersive tale of power, politics, and self-discovery.\n"
     ]
    }
   ],
   "source": [
    "result = chain.invoke({\n",
    "    \"theme\":\"Political tension/ Power strugle\",\n",
    "    \"character\":\"arjun, a student from todays world\",\n",
    "    \"setting\":\"arjun is reincarnated into a world full of magicals creatures and the era can be similar to midiviel times were swords and arrows were used. the world consists of 3 continents\"\n",
    "})\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
